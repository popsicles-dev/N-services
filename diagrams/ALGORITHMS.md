# SEO Lead Generation System - Algorithm Specifications

| Algorithm Name | Details |
|----------------|---------|
| **1. PainScoreCalculation (SEO Ranking)** | **Input:** MobileMetrics, DesktopMetrics, PerformanceScores<br>**Output:** PainScore (0-100)<br><br>**Pseudocode:**<br>`1: procedure PainScoreCalculation(Row)`<br>`2:     // Extract and normalize mobile metrics`<br>`3:     Mobile_LCP ← ConvertToSeconds(Row.Mobile_LCP)`<br>`4:     Mobile_FCP ← ConvertToSeconds(Row.Mobile_FCP)`<br>`5:     Mobile_CLS ← ParseFloat(Row.Mobile_CLS)`<br>`6:     Mobile_TBT ← ConvertToSeconds(Row.Mobile_TBT)`<br>`7:     Mobile_TTI ← ConvertToSeconds(Row.Mobile_TTI)`<br>`8:     Mobile_SI ← ConvertToSeconds(Row.Mobile_SpeedIndex)`<br>`9:     `<br>`10:    // Normalize to 0-1 scale using CWV thresholds`<br>`11:    LCP_norm ← min(Mobile_LCP / 4.0, 1.0)`<br>`12:    FCP_norm ← min(Mobile_FCP / 3.0, 1.0)`<br>`13:    CLS_norm ← min(Mobile_CLS / 0.25, 1.0)`<br>`14:    TBT_norm ← min(Mobile_TBT / 0.6, 1.0)`<br>`15:    TTI_norm ← min(Mobile_TTI / 7.3, 1.0)`<br>`16:    SI_norm ← min(Mobile_SI / 5.8, 1.0)`<br>`17:    `<br>`18:    // Calculate weighted mobile pain`<br>`19:    MobilePain ← LCP_norm×0.20 + TBT_norm×0.10 + FCP_norm×0.10`<br>`20:                 + TTI_norm×0.10 + CLS_norm×0.05 + SI_norm×0.05`<br>`21:    `<br>`22:    // Calculate desktop pain (similar process)`<br>`23:    DesktopPain ← DesktopLCP_norm×0.15 + DesktopTBT_norm×0.07`<br>`24:                  + DesktopFCP_norm×0.05 + DesktopTTI_norm×0.05`<br>`25:                  + DesktopCLS_norm×0.02 + DesktopSI_norm×0.01`<br>`26:    `<br>`27:    // Performance pain (inverse of scores)`<br>`28:    PerfPain ← (1 - MobileScore/100)×0.25 + (1 - DesktopScore/100)×0.15`<br>`29:    `<br>`30:    // Final weighted combination`<br>`31:    TotalPain ← MobilePain×0.60 + DesktopPain×0.35 + PerfPain×0.40`<br>`32:    PainScore ← round(TotalPain × 100, 2)`<br>`33:    return PainScore`<br>`34: end procedure` |
| **2. IntentScoringWithLLM (AI Lead Qualification)** | **Input:** AuditData (URL, Title, H1, MetaDescription)<br>**Output:** {score: 1-10, justification: string}<br><br>**Pseudocode:**<br>`1: procedure IntentScoringWithLLM(AuditData)`<br>`2:     try`<br>`3:         StructuralData ← JSON.stringify(AuditData)`<br>`4:         `<br>`5:         SystemPrompt ← "You are an Elite SEO Lead Qualification Expert..."`<br>`6:         UserPrompt ← "Assign a score 1-10 based on:\n"`<br>`7:                      + "- High Potential (8-10): Missing title, H1, generic content\n"`<br>`8:                      + "- Medium (5-7): Minor structural issues\n"`<br>`9:                      + "- Low (1-4): All elements present and customized\n"`<br>`10:                     + "AUDIT_DATA: " + StructuralData`<br>`11:        `<br>`12:        Messages ← [`<br>`13:            {role: "system", content: SystemPrompt},`<br>`14:            {role: "user", content: UserPrompt}`<br>`15:        ]`<br>`16:        `<br>`17:        Response ← GroqAPI.chat.completions.create(`<br>`18:            model="llama-3.1-8b-instant",`<br>`19:            messages=Messages,`<br>`20:            response_format={type: "json_object"},`<br>`21:            temperature=0.0,`<br>`22:            max_tokens=200`<br>`23:        )`<br>`24:        `<br>`25:        Result ← JSON.parse(Response.choices[0].message.content)`<br>`26:        return {score: Result.score, justification: Result.justification}`<br>`27:    catch Exception as e`<br>`28:        return {score: 0, justification: "Error: " + e.message}`<br>`29:    end try`<br>`30: end procedure` |
| **3. ContactExtractionWithRegex (Data Mining)** | **Input:** HTMLText<br>**Output:** {emails: [], phones: []}<br><br>**Pseudocode:**<br>`1: procedure ContactExtractionWithRegex(Text)`<br>`2:     // Email pattern matching`<br>`3:     EmailPattern ← "[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}"`<br>`4:     Emails ← Set(RegexFindAll(EmailPattern, Text))`<br>`5:     `<br>`6:     // Phone pattern matching (US format)`<br>`7:     PhonePattern ← "(\(?\d{3}\)?[-.\s]\d{3}[-.\s]\d{4})"`<br>`8:     Phones ← Set(RegexFindAll(PhonePattern, Text))`<br>`9:     `<br>`10:    return {emails: List(Emails), phones: List(Phones)}`<br>`11: end procedure` |
| **4. FocusedWebCrawler (Contact Enrichment)** | **Input:** BaseURL<br>**Output:** {emails: [], phones: [], social_media: {}}<br><br>**Pseudocode:**<br>`1: procedure FocusedWebCrawler(BaseURL)`<br>`2:     Results ← {emails: [], phones: [], social_media: {}}`<br>`3:     `<br>`4:     // Define priority pages to crawl`<br>`5:     URLsToCheck ← [BaseURL, BaseURL+"/contact",`<br>`6:                    BaseURL+"/about-us", BaseURL+"/contact-us"]`<br>`7:     `<br>`8:     for each URL in URLsToCheck do`<br>`9:         try`<br>`10:            Response ← HTTP.GET(URL, timeout=7s)`<br>`11:            if Response.status = 200 then`<br>`12:                Soup ← ParseHTML(Response.content)`<br>`13:                PageText ← Soup.getText()`<br>`14:                `<br>`15:                // Extract contacts`<br>`16:                Contacts ← ContactExtractionWithRegex(PageText)`<br>`17:                Results.emails ← Union(Results.emails, Contacts.emails)`<br>`18:                Results.phones ← Union(Results.phones, Contacts.phones)`<br>`19:                `<br>`20:                // Extract social links`<br>`21:                if Results.social_media is empty then`<br>`22:                    Results.social_media ← SocialLinkExtraction(Soup)`<br>`23:                end if`<br>`24:                `<br>`25:                // Early exit if contacts found`<br>`26:                if (Results.emails or Results.phones) and URL ≠ BaseURL then`<br>`27:                    break`<br>`28:                end if`<br>`29:            end if`<br>`30:        catch RequestException`<br>`31:            continue`<br>`32:        end try`<br>`33:    end for`<br>`34:    return Results`<br>`35: end procedure` |
| **5. SocialLinkExtraction (DOM Parsing)** | **Input:** BeautifulSoupObject<br>**Output:** {Facebook: URL, Twitter: URL, ...}<br><br>**Pseudocode:**<br>`1: procedure SocialLinkExtraction(Soup)`<br>`2:     SocialMedia ← {}`<br>`3:     Platforms ← {`<br>`4:         "facebook.com": "Facebook",`<br>`5:         "twitter.com": "Twitter",`<br>`6:         "linkedin.com/company": "LinkedIn",`<br>`7:         "instagram.com": "Instagram"`<br>`8:     }`<br>`9:     `<br>`10:    for each Link in Soup.findAll("a", href=True) do`<br>`11:        Href ← Link.href.toLowerCase()`<br>`12:        for each (Domain, Name) in Platforms do`<br>`13:            if Domain in Href and Name not in SocialMedia then`<br>`14:                SocialMedia[Name] ← Href`<br>`15:            end if`<br>`16:        end for`<br>`17:    end for`<br>`18:    return SocialMedia`<br>`19: end procedure` |
| **6. RAGSemanticSearch (Chatbot Retrieval)** | **Input:** UserQuery, TopK=5<br>**Output:** RelevantContext<br><br>**Pseudocode:**<br>`1: procedure RAGSemanticSearch(Query, TopK=5)`<br>`2:     // Embed user query using sentence transformer`<br>`3:     QueryVector ← SentenceTransformer.encode(Query)`<br>`4:     `<br>`5:     // Search ChromaDB with cosine similarity`<br>`6:     Results ← ChromaDB.Collection.query(`<br>`7:         query_embeddings=QueryVector,`<br>`8:         n_results=TopK`<br>`9:     )`<br>`10:    `<br>`11:    // Concatenate retrieved documents`<br>`12:    Documents ← Results.documents[0]`<br>`13:    Context ← Join(Documents, separator="\n\n")`<br>`14:    return Context`<br>`15: end procedure` |
| **7. RAGAnswerGeneration (AI Chatbot)** | **Input:** UserQuery, ConversationHistory<br>**Output:** SEOExpertAnswer<br><br>**Pseudocode:**<br>`1: procedure RAGAnswerGeneration(Query, History=[])`<br>`2:     // Retrieve relevant context`<br>`3:     Context ← RAGSemanticSearch(Query, TopK=5)`<br>`4:     `<br>`5:     // Build conversation history string`<br>`6:     HistoryStr ← ""`<br>`7:     for each H in History do`<br>`8:         HistoryStr += "User: " + H.question + "\n"`<br>`9:         HistoryStr += "Assistant: " + H.answer + "\n"`<br>`10:    end for`<br>`11:    `<br>`12:    // Construct prompt`<br>`13:    Prompt ← "You are an Elite SEO Expert...\n"`<br>`14:             + "KNOWLEDGE HISTORY:\n" + HistoryStr`<br>`15:             + "USER QUERY:\n" + Query`<br>`16:             + "RELEVANT KNOWLEDGE:\n" + Context`<br>`17:    `<br>`18:    // Generate answer via LLM`<br>`19:    Response ← GroqAPI.chat.completions.create(`<br>`20:        model="llama-3.1-8b-instant",`<br>`21:        messages=[{role: "user", content: Prompt}],`<br>`22:        max_tokens=500`<br>`23:    )`<br>`24:    return Response.choices[0].message.content`<br>`25: end procedure` |
| **8. SEOStructuralAudit (Web Analysis)** | **Input:** WebsiteURL<br>**Output:** {title, meta_description, h1, word_count, status}<br><br>**Pseudocode:**<br>`1: procedure SEOStructuralAudit(URL)`<br>`2:     try`<br>`3:         if not URL.startsWith("http") then`<br>`4:             URL ← "https://" + URL`<br>`5:         end if`<br>`6:         `<br>`7:         Response ← HTTP.GET(URL, timeout=7s)`<br>`8:         if Response.status ≠ 200 then`<br>`9:             return {status: "Failed", error: Response.status}`<br>`10:        end if`<br>`11:        `<br>`12:        Soup ← ParseHTML(Response.content)`<br>`13:        `<br>`14:        // Extract SEO elements`<br>`15:        Title ← Soup.find("title").text or "MISSING"`<br>`16:        MetaDesc ← Soup.find("meta[name=description]").content or "MISSING"`<br>`17:        H1 ← Soup.find("h1").text or "MISSING"`<br>`18:        WordCount ← length(Soup.getText().split())`<br>`19:        `<br>`20:        return {`<br>`21:            title: Title,`<br>`22:            title_length: length(Title),`<br>`23:            meta_description: MetaDesc,`<br>`24:            h1_content: H1,`<br>`25:            word_count: WordCount,`<br>`26:            status: "Completed"`<br>`27:        }`<br>`28:    catch TimeoutException`<br>`29:        return {status: "Timeout"}`<br>`30:    catch Exception as e`<br>`31:        return {status: "Failed", error: e.message}`<br>`32:    end try`<br>`33: end procedure` |
| **9. JWTAuthentication (Security)** | **Input:** UserCredentials or Token<br>**Output:** AccessToken or ValidationResult<br><br>**Pseudocode:**<br>`1: procedure HashPassword(PlainPassword)`<br>`2:     return bcrypt.hash(PlainPassword, rounds=12)`<br>`3: end procedure`<br>`4: `<br>`5: procedure VerifyPassword(PlainPassword, HashedPassword)`<br>`6:     return bcrypt.verify(PlainPassword, HashedPassword)`<br>`7: end procedure`<br>`8: `<br>`9: procedure CreateAccessToken(UserData, ExpiresDelta=30min)`<br>`10:    Payload ← {`<br>`11:        sub: UserData.id,`<br>`12:        exp: CurrentTime + ExpiresDelta,`<br>`13:        type: "access"`<br>`14:    }`<br>`15:    Token ← JWT.encode(Payload, SECRET_KEY, algorithm="HS256")`<br>`16:    return Token`<br>`17: end procedure`<br>`18: `<br>`19: procedure VerifyToken(Token, TokenType="access")`<br>`20:    try`<br>`21:        Payload ← JWT.decode(Token, SECRET_KEY, algorithms=["HS256"])`<br>`22:        if Payload.type ≠ TokenType then`<br>`23:            return None`<br>`24:        end if`<br>`25:        return Payload`<br>`26:    catch JWTError`<br>`27:        return None`<br>`28:    end try`<br>`29: end procedure` |
